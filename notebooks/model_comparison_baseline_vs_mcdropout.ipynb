{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13f1da54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jejer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.1+cpu\n",
      "GPU available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2bd09a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "\n",
      "Baseline (no dropout): notlath/BioClinical-ModernBERT-base-Symptom2Disease_WITHOUT-DROPOUT-42\n",
      "Enhanced (MC dropout): notlath/BioClinical-ModernBERT-base-Symptom2Disease_WITH-DROPOUT-42\n",
      "\n",
      "MC Samples: 50\n",
      "Dropout Rate: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Model paths\n",
    "BASELINE_MODEL_PATH = \"notlath/BioClinical-ModernBERT-base-Symptom2Disease_WITHOUT-DROPOUT-42\"\n",
    "ENHANCED_MODEL_PATH = \"notlath/BioClinical-ModernBERT-base-Symptom2Disease_WITH-DROPOUT-42\"\n",
    "\n",
    "# Configuration\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "ALLOWED_DISEASES = {\"Dengue\", \"Pneumonia\", \"Typhoid\", \"Impetigo\"}\n",
    "N_MC_SAMPLES = 50  # Number of stochastic forward passes\n",
    "INFERENCE_DROPOUT_RATE = 0.10  # Dropout rate during inference\n",
    "MAX_LEN = 512\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"\\nBaseline (no dropout): {BASELINE_MODEL_PATH}\")\n",
    "print(f\"Enhanced (MC dropout): {ENHANCED_MODEL_PATH}\")\n",
    "print(f\"\\nMC Samples: {N_MC_SAMPLES}\")\n",
    "print(f\"Dropout Rate: {INFERENCE_DROPOUT_RATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6357047",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineClassifier:\n",
    "    \"\"\"Standard inference - deterministic predictions (no dropout).\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path: str, device: str = DEVICE):\n",
    "        print(f\"Loading baseline model from {model_path}...\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "        self.model.eval().to(device)\n",
    "        self.device = device\n",
    "        print(\"‚úì Baseline model loaded\")\n",
    "\n",
    "    def predict(self, text: str):\n",
    "        inputs = self.tokenizer(\n",
    "            text, return_tensors=\"pt\", padding=True, truncation=True, max_length=MAX_LEN\n",
    "        ).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(**inputs).logits\n",
    "            probs = F.softmax(logits, dim=-1)[0]\n",
    "        \n",
    "        confidences = probs.detach().cpu().numpy()\n",
    "        pred_idx = int(confidences.argmax())\n",
    "        pred_label = self.model.config.id2label[pred_idx]\n",
    "        \n",
    "        # Filter to allowed diseases\n",
    "        allowed = []\n",
    "        for idx, label in self.model.config.id2label.items():\n",
    "            if label in ALLOWED_DISEASES:\n",
    "                allowed.append((label, float(confidences[idx])))\n",
    "        allowed.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return {\n",
    "            \"predicted_label\": pred_label,\n",
    "            \"confidence\": float(confidences[pred_idx]),\n",
    "            \"probabilities\": confidences.tolist(),\n",
    "            \"top_allowed\": allowed,\n",
    "        }\n",
    "    \n",
    "    def count_dropout_layers(self):\n",
    "        \"\"\"Count dropout layers in model.\"\"\"\n",
    "        count = 0\n",
    "        for module in self.model.modules():\n",
    "            if \"Dropout\" in module.__class__.__name__:\n",
    "                count += 1\n",
    "        return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2734c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropoutClassifier:\n",
    "    \"\"\"MC Dropout inference with uncertainty quantification.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path: str, device: str = DEVICE, \n",
    "                 n_iterations: int = N_MC_SAMPLES, \n",
    "                 inference_dropout_rate: float = INFERENCE_DROPOUT_RATE):\n",
    "        print(f\"Loading enhanced model from {model_path}...\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "        self.device = device\n",
    "        self.n_iterations = n_iterations\n",
    "        self.inference_dropout_rate = inference_dropout_rate\n",
    "        print(\"‚úì Enhanced model loaded\")\n",
    "\n",
    "    def enable_mc_dropout(self):\n",
    "        \"\"\"Enable dropout for MC sampling.\"\"\"\n",
    "        for module in self.model.modules():\n",
    "            if module.__class__.__name__.startswith(\"Dropout\"):\n",
    "                module.p = self.inference_dropout_rate\n",
    "                module.train()\n",
    "            elif \"Norm\" in module.__class__.__name__:\n",
    "                module.eval()\n",
    "\n",
    "    def compute_mutual_information(self, predictions: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"MI = H(mean probs) - E[H(sample probs)].\"\"\"\n",
    "        expected_entropy = np.mean([entropy(p, axis=-1) for p in predictions], axis=0)\n",
    "        mean_probs = predictions.mean(axis=0)\n",
    "        entropy_of_expected = entropy(mean_probs, axis=-1)\n",
    "        return entropy_of_expected - expected_entropy\n",
    "\n",
    "    def predict_with_uncertainty(self, text: str):\n",
    "        inputs = self.tokenizer(\n",
    "            text, return_tensors=\"pt\", truncation=True, padding=True, max_length=MAX_LEN\n",
    "        ).to(self.device)\n",
    "        inputs[\"input_ids\"] = inputs[\"input_ids\"].to(torch.long)\n",
    "        inputs[\"attention_mask\"] = inputs[\"attention_mask\"].to(torch.long)\n",
    "\n",
    "        self.enable_mc_dropout()\n",
    "        all_predictions = []\n",
    "        with torch.no_grad():\n",
    "            for _ in range(self.n_iterations):\n",
    "                probs = torch.softmax(self.model(**inputs).logits, dim=-1)\n",
    "                all_predictions.append(probs.cpu().numpy())\n",
    "        \n",
    "        all_predictions = np.stack(all_predictions)  # (n_iter, batch, classes)\n",
    "        mean_probs = all_predictions.mean(axis=0)\n",
    "        std_probs = all_predictions.std(axis=0)\n",
    "        pred_idx = mean_probs.argmax(axis=-1)\n",
    "        confidence = mean_probs.max(axis=-1)\n",
    "        predictive_entropy = entropy(mean_probs, axis=-1)\n",
    "        mutual_information = self.compute_mutual_information(all_predictions)\n",
    "\n",
    "        # Filter to allowed diseases\n",
    "        allowed = []\n",
    "        probs_vec = mean_probs[0]\n",
    "        for idx, label in self.model.config.id2label.items():\n",
    "            if label in ALLOWED_DISEASES:\n",
    "                allowed.append((label, float(probs_vec[idx])))\n",
    "        allowed.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        return {\n",
    "            \"predicted_label\": self.model.config.id2label[int(pred_idx[0])],\n",
    "            \"confidence\": float(confidence[0]),\n",
    "            \"mean_probs\": mean_probs[0],\n",
    "            \"std_probs\": std_probs[0],\n",
    "            \"predictive_entropy\": float(predictive_entropy[0]),\n",
    "            \"mutual_information\": float(mutual_information[0]),\n",
    "            \"top_allowed\": allowed,\n",
    "        }\n",
    "    \n",
    "    def count_dropout_layers(self):\n",
    "        \"\"\"Count dropout layers in model.\"\"\"\n",
    "        count = 0\n",
    "        for module in self.model.modules():\n",
    "            if \"Dropout\" in module.__class__.__name__:\n",
    "                count += 1\n",
    "        return count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeee6c8",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81d3fc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading baseline model from notlath/BioClinical-ModernBERT-base-Symptom2Disease_WITHOUT-DROPOUT-42...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Baseline model loaded\n",
      "Dropout layers: 24\n",
      "\n",
      "Loading enhanced model from notlath/BioClinical-ModernBERT-base-Symptom2Disease_WITH-DROPOUT-42...\n",
      "‚úì Enhanced model loaded\n",
      "Dropout layers: 46\n"
     ]
    }
   ],
   "source": [
    "baseline_model = BaselineClassifier(BASELINE_MODEL_PATH, device=DEVICE)\n",
    "print(f\"Dropout layers: {baseline_model.count_dropout_layers()}\")\n",
    "\n",
    "print()\n",
    "\n",
    "mc_model = MCDropoutClassifier(\n",
    "    ENHANCED_MODEL_PATH, \n",
    "    device=DEVICE, \n",
    "    n_iterations=N_MC_SAMPLES, \n",
    "    inference_dropout_rate=INFERENCE_DROPOUT_RATE\n",
    ")\n",
    "print(f\"Dropout layers: {mc_model.count_dropout_layers()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a74905f",
   "metadata": {},
   "source": [
    "## Architecture Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "995d5d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ARCHITECTURE COMPARISON\n",
      "======================================================================\n",
      "\n",
      "[BASELINE MODEL]\n",
      "  Model: BioClinical-ModernBERT-base-Symptom2Disease_WITHOUT-DROPOUT-42\n",
      "  Dropout layers: 24\n",
      "  Mode: eval()\n",
      "  Training flag: False\n",
      "  Behavior: Deterministic predictions (same input ‚Üí same output)\n",
      "\n",
      "[ENHANCED MODEL]\n",
      "  Model: BioClinical-ModernBERT-base-Symptom2Disease_WITH-DROPOUT-42\n",
      "  Dropout layers: 46\n",
      "  Inference dropout rate: 0.1\n",
      "  MC samples: 50\n",
      "  Mode: eval() initially, then dropout layers set to train()\n",
      "  Behavior: Stochastic predictions (same input ‚Üí distribution of outputs)\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ARCHITECTURE COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n[BASELINE MODEL]\")\n",
    "print(f\"  Model: {BASELINE_MODEL_PATH.split('/')[-1]}\")\n",
    "print(f\"  Dropout layers: {baseline_model.count_dropout_layers()}\")\n",
    "print(f\"  Mode: eval()\")\n",
    "print(f\"  Training flag: {baseline_model.model.training}\")\n",
    "print(f\"  Behavior: Deterministic predictions (same input ‚Üí same output)\")\n",
    "\n",
    "print(\"\\n[ENHANCED MODEL]\")\n",
    "print(f\"  Model: {ENHANCED_MODEL_PATH.split('/')[-1]}\")\n",
    "print(f\"  Dropout layers: {mc_model.count_dropout_layers()}\")\n",
    "print(f\"  Inference dropout rate: {INFERENCE_DROPOUT_RATE}\")\n",
    "print(f\"  MC samples: {N_MC_SAMPLES}\")\n",
    "print(f\"  Mode: eval() initially, then dropout layers set to train()\")\n",
    "print(f\"  Behavior: Stochastic predictions (same input ‚Üí distribution of outputs)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480cdb99",
   "metadata": {},
   "source": [
    "## Prediction Comparison on Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06805857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TEST 1: CLEAR - Classic dengue presentation\n",
      "======================================================================\n",
      "Input: \"High fever, severe headache, muscle pain, joint pain, rash on chest and limbs\"\n",
      "\n",
      "[BASELINE - Deterministic]\n",
      "  Prediction: Dengue\n",
      "  Confidence: 0.5255\n",
      "  Top 3 diseases: [('Dengue', '0.5255'), ('Typhoid', '0.2354'), ('Pneumonia', '0.0459')]\n",
      "\n",
      "[ENHANCED - MC Dropout]\n",
      "  Prediction: Dengue\n",
      "  Mean confidence: 0.6875\n",
      "  Confidence std: 0.1424\n",
      "  Predictive entropy: 1.1002\n",
      "  Mutual information: 0.0659\n",
      "  Top 3 diseases: [('Dengue', '0.6875'), ('Typhoid', '0.1049'), ('Pneumonia', '0.0593')]\n",
      "\n",
      "======================================================================\n",
      "TEST 2: AMBIGUOUS - Non-specific symptoms\n",
      "======================================================================\n",
      "Input: \"Fever and cough\"\n",
      "\n",
      "[BASELINE - Deterministic]\n",
      "  Prediction: Influenza\n",
      "  Confidence: 0.5023\n",
      "  Top 3 diseases: [('Pneumonia', '0.1125'), ('Typhoid', '0.1124'), ('Dengue', '0.0460')]\n",
      "\n",
      "[ENHANCED - MC Dropout]\n",
      "  Prediction: Pneumonia\n",
      "  Mean confidence: 0.3971\n",
      "  Confidence std: 0.1793\n",
      "  Predictive entropy: 1.5266\n",
      "  Mutual information: 0.1647\n",
      "  Top 3 diseases: [('Pneumonia', '0.3971'), ('Dengue', '0.2287'), ('Typhoid', '0.0628')]\n",
      "\n",
      "======================================================================\n",
      "TEST 3: MODERATE - Suggestive of typhoid\n",
      "======================================================================\n",
      "Input: \"Sudden high fever, chills, rose spots on abdomen, sustained fever pattern\"\n",
      "\n",
      "[BASELINE - Deterministic]\n",
      "  Prediction: Typhoid\n",
      "  Confidence: 0.8190\n",
      "  Top 3 diseases: [('Typhoid', '0.8190'), ('Pneumonia', '0.0311'), ('Dengue', '0.0153')]\n",
      "\n",
      "[ENHANCED - MC Dropout]\n",
      "  Prediction: Typhoid\n",
      "  Mean confidence: 0.8157\n",
      "  Confidence std: 0.1103\n",
      "  Predictive entropy: 0.7680\n",
      "  Mutual information: 0.0481\n",
      "  Top 3 diseases: [('Typhoid', '0.8157'), ('Pneumonia', '0.0358'), ('Dengue', '0.0281')]\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "test_cases = [\n",
    "    {\n",
    "        \"text\": \"High fever, severe headache, muscle pain, joint pain, rash on chest and limbs\",\n",
    "        \"clarity\": \"CLEAR\",\n",
    "        \"description\": \"Classic dengue presentation\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Fever and cough\",\n",
    "        \"clarity\": \"AMBIGUOUS\",\n",
    "        \"description\": \"Non-specific symptoms\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Sudden high fever, chills, rose spots on abdomen, sustained fever pattern\",\n",
    "        \"clarity\": \"MODERATE\",\n",
    "        \"description\": \"Suggestive of typhoid\"\n",
    "    },\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for idx, test in enumerate(test_cases, 1):\n",
    "    text = test[\"text\"]\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"TEST {idx}: {test['clarity']} - {test['description']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Input: \\\"{text}\\\"\")\n",
    "    \n",
    "    # Baseline prediction\n",
    "    b = baseline_model.predict(text)\n",
    "    print(f\"\\n[BASELINE - Deterministic]\")\n",
    "    print(f\"  Prediction: {b['predicted_label']}\")\n",
    "    print(f\"  Confidence: {b['confidence']:.4f}\")\n",
    "    print(f\"  Top 3 diseases: {[(d, f'{p:.4f}') for d, p in b['top_allowed'][:3]]}\")\n",
    "    \n",
    "    # Enhanced prediction\n",
    "    m = mc_model.predict_with_uncertainty(text)\n",
    "    print(f\"\\n[ENHANCED - MC Dropout]\")\n",
    "    print(f\"  Prediction: {m['predicted_label']}\")\n",
    "    print(f\"  Mean confidence: {m['confidence']:.4f}\")\n",
    "    print(f\"  Confidence std: {m['std_probs'].max():.4f}\")\n",
    "    print(f\"  Predictive entropy: {m['predictive_entropy']:.4f}\")\n",
    "    print(f\"  Mutual information: {m['mutual_information']:.4f}\")\n",
    "    print(f\"  Top 3 diseases: {[(d, f'{p:.4f}') for d, p in m['top_allowed'][:3]]}\")\n",
    "    \n",
    "    results.append({\n",
    "        \"clarity\": test['clarity'],\n",
    "        \"text\": text[:40] + \"...\",\n",
    "        \"baseline_pred\": b['predicted_label'],\n",
    "        \"baseline_conf\": b['confidence'],\n",
    "        \"enhanced_pred\": m['predicted_label'],\n",
    "        \"enhanced_conf\": m['confidence'],\n",
    "        \"enhanced_std\": m['std_probs'].max(),\n",
    "        \"enhanced_entropy\": m['predictive_entropy'],\n",
    "        \"enhanced_mi\": m['mutual_information'],\n",
    "    })\n",
    "\n",
    "print(f\"\\n{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef2ece6",
   "metadata": {},
   "source": [
    "## Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "752cba49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  clarity                                        text baseline_pred  baseline_conf enhanced_pred  enhanced_conf  enhanced_std  enhanced_entropy  enhanced_mi  conf_diff\n",
      "    CLEAR High fever, severe headache, muscle pain...        Dengue       0.525517        Dengue       0.687472      0.142410          1.100218     0.065918   0.161955\n",
      "AMBIGUOUS                          Fever and cough...     Influenza       0.502250     Pneumonia       0.397115      0.179302          1.526615     0.164663  -0.105135\n",
      " MODERATE Sudden high fever, chills, rose spots on...       Typhoid       0.818974       Typhoid       0.815679      0.110270          0.767987     0.048126  -0.003295\n",
      "\n",
      "======================================================================\n",
      "KEY OBSERVATIONS\n",
      "======================================================================\n",
      "1. CLEAR cases: Enhanced should show LOW entropy/MI (model is certain)\n",
      "2. AMBIGUOUS cases: Enhanced should show HIGH entropy/MI (model is uncertain)\n",
      "3. Baseline provides NO uncertainty quantification\n",
      "4. Enhanced provides principled uncertainty measures via MC sampling\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df['conf_diff'] = df['enhanced_conf'] - df['baseline_conf']\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY OBSERVATIONS\")\n",
    "print(\"=\"*70)\n",
    "print(\"1. CLEAR cases: Enhanced should show LOW entropy/MI (model is certain)\")\n",
    "print(\"2. AMBIGUOUS cases: Enhanced should show HIGH entropy/MI (model is uncertain)\")\n",
    "print(\"3. Baseline provides NO uncertainty quantification\")\n",
    "print(\"4. Enhanced provides principled uncertainty measures via MC sampling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99566c79",
   "metadata": {},
   "source": [
    "## Stability Test: Repeated Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41d5c4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing prediction stability for: \"Fever and cough\"\n",
      "Running 10 predictions with each model...\n",
      "\n",
      "[BASELINE] - Expected: All predictions identical (deterministic)\n",
      "  Run 1: Influenza    | Confidence: 0.5023\n",
      "  Run 2: Influenza    | Confidence: 0.5023\n",
      "  Run 3: Influenza    | Confidence: 0.5023\n",
      "  ...\n",
      "  Run 10: Influenza    | Confidence: 0.5023\n",
      "\n",
      "  Confidence variance: 0.00000000\n",
      "  All identical: True\n",
      "\n",
      "[ENHANCED] - Expected: Predictions vary (stochastic ensemble)\n",
      "  Run 1: Pneumonia    | Conf: 0.4063 | Entropy: 1.5297\n",
      "  Run 2: Pneumonia    | Conf: 0.3381 | Entropy: 1.5586\n",
      "  Run 3: Pneumonia    | Conf: 0.3867 | Entropy: 1.5214\n",
      "  ...\n",
      "  Run 10: Pneumonia    | Conf: 0.3652 | Entropy: 1.5641\n",
      "\n",
      "  Confidence variance: 0.00123924\n",
      "  Entropy variance: 0.00129848\n",
      "\n",
      "======================================================================\n",
      "INTERPRETATION\n",
      "======================================================================\n",
      "Baseline variance ‚âà 0: Deterministic (no randomness)\n",
      "Enhanced variance > 0: Stochastic ensemble captures epistemic uncertainty\n",
      "\n",
      "The variance in Enhanced predictions is NOT a bug - it's the feature!\n",
      "MC Dropout creates an ensemble of models to quantify uncertainty.\n"
     ]
    }
   ],
   "source": [
    "test_text = \"Fever and cough\"  # Ambiguous case\n",
    "\n",
    "print(f\"Testing prediction stability for: \\\"{test_text}\\\"\")\n",
    "print(f\"Running 10 predictions with each model...\\n\")\n",
    "\n",
    "# Baseline - should be identical\n",
    "print(\"[BASELINE] - Expected: All predictions identical (deterministic)\")\n",
    "baseline_preds = []\n",
    "for i in range(10):\n",
    "    pred = baseline_model.predict(test_text)\n",
    "    baseline_preds.append(pred['confidence'])\n",
    "    if i < 3 or i == 9:\n",
    "        print(f\"  Run {i+1}: {pred['predicted_label']:12s} | Confidence: {pred['confidence']:.4f}\")\n",
    "    elif i == 3:\n",
    "        print(f\"  ...\")\n",
    "\n",
    "print(f\"\\n  Confidence variance: {np.var(baseline_preds):.8f}\")\n",
    "print(f\"  All identical: {len(set(baseline_preds)) == 1}\")\n",
    "\n",
    "# Enhanced - should vary\n",
    "print(f\"\\n[ENHANCED] - Expected: Predictions vary (stochastic ensemble)\")\n",
    "enhanced_preds = []\n",
    "enhanced_entropies = []\n",
    "for i in range(10):\n",
    "    pred = mc_model.predict_with_uncertainty(test_text)\n",
    "    enhanced_preds.append(pred['confidence'])\n",
    "    enhanced_entropies.append(pred['predictive_entropy'])\n",
    "    if i < 3 or i == 9:\n",
    "        print(f\"  Run {i+1}: {pred['predicted_label']:12s} | Conf: {pred['confidence']:.4f} | Entropy: {pred['predictive_entropy']:.4f}\")\n",
    "    elif i == 3:\n",
    "        print(f\"  ...\")\n",
    "\n",
    "print(f\"\\n  Confidence variance: {np.var(enhanced_preds):.8f}\")\n",
    "print(f\"  Entropy variance: {np.var(enhanced_entropies):.8f}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Baseline variance ‚âà 0: Deterministic (no randomness)\")\n",
    "print(f\"Enhanced variance > 0: Stochastic ensemble captures epistemic uncertainty\")\n",
    "print(f\"\\nThe variance in Enhanced predictions is NOT a bug - it's the feature!\")\n",
    "print(f\"MC Dropout creates an ensemble of models to quantify uncertainty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf26a847",
   "metadata": {},
   "source": [
    "## Key Findings\n",
    "\n",
    "### 1. **Architectural Difference**\n",
    "- **Baseline**: Trained WITHOUT dropout ‚Üí Deterministic inference\n",
    "- **Enhanced**: Trained WITH dropout ‚Üí Stochastic inference via MC sampling\n",
    "\n",
    "### 2. **Uncertainty Quantification**\n",
    "- **Baseline**: Single point estimate, no uncertainty measure\n",
    "- **Enhanced**: Distributional predictions with:\n",
    "  - **Predictive Entropy**: Overall uncertainty in prediction\n",
    "  - **Mutual Information**: Model's epistemic uncertainty (knowledge gaps)\n",
    "  - **Confidence Std**: Variability across MC samples\n",
    "\n",
    "### 3. **Clinical Implications**\n",
    "- **Clear cases**: Both models confident, Enhanced provides additional safety bounds\n",
    "- **Ambiguous cases**: \n",
    "  - Baseline: False confidence (no way to know it's uncertain)\n",
    "  - Enhanced: Quantified uncertainty (can trigger human review)\n",
    "\n",
    "### 4. **Recommended Usage**\n",
    "- Use **entropy/MI thresholds** to flag uncertain cases\n",
    "- Route high-uncertainty predictions to clinician review\n",
    "- Trust high-confidence, low-entropy predictions for automated triage\n",
    "\n",
    "### 5. **Trade-offs**\n",
    "- **Computational**: Enhanced requires 50x more inference time (50 forward passes)\n",
    "- **Benefit**: Principled uncertainty quantification for safety-critical applications\n",
    "- **Solution**: Hybrid approach - use baseline for screening, enhanced for borderline cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65690e93",
   "metadata": {},
   "source": [
    "## BONUS: Baseline vs Enhanced with SHAP Explainability\n",
    "\n",
    "**Research Question**: Does adding SHAP explanations improve clinical interpretability without changing predictions?\n",
    "\n",
    "**Comparison Framework**:\n",
    "- **Baseline**: Softmax output only (prediction + confidence)\n",
    "- **Enhanced**: Softmax + SHAP (prediction + confidence + token attributions)\n",
    "\n",
    "**Key Insight**: Both models produce identical predictions - SHAP adds *post-hoc* explainability to understand *why* the model made that prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a1a8021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì SHAP comparison classes loaded\n"
     ]
    }
   ],
   "source": [
    "# Import SHAP dependencies\n",
    "from captum.attr import GradientShap\n",
    "\n",
    "class BaselineClassifierSoftmaxOnly:\n",
    "    \"\"\"Baseline: Only returns predictions, no explanations.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path: str, device: str = DEVICE):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "        self.model.eval().to(device)\n",
    "        self.device = device\n",
    "    \n",
    "    def predict(self, text: str):\n",
    "        inputs = self.tokenizer(\n",
    "            text, return_tensors=\"pt\", padding=True, truncation=True, max_length=MAX_LEN\n",
    "        ).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(**inputs).logits\n",
    "            probs = F.softmax(logits, dim=-1)[0]\n",
    "        \n",
    "        confidences = probs.detach().cpu().numpy()\n",
    "        pred_idx = int(confidences.argmax())\n",
    "        pred_label = self.model.config.id2label[pred_idx]\n",
    "        \n",
    "        return {\n",
    "            \"predicted_label\": pred_label,\n",
    "            \"confidence\": float(confidences[pred_idx]),\n",
    "            \"explanation\": \"‚ö†Ô∏è No explanation available (softmax only)\"\n",
    "        }\n",
    "\n",
    "\n",
    "class EnhancedClassifierWithSHAP:\n",
    "    \"\"\"Enhanced: Returns predictions + SHAP explanations.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path: str, device: str = DEVICE):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "        self.model.eval().to(device)\n",
    "        self.device = device\n",
    "    \n",
    "    def predict_with_explanation(self, text: str):\n",
    "        inputs = self.tokenizer(\n",
    "            text, return_tensors=\"pt\", padding=True, truncation=True, max_length=MAX_LEN\n",
    "        ).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = self.model(**inputs).logits\n",
    "            probs = F.softmax(logits, dim=-1)[0]\n",
    "        \n",
    "        confidences = probs.detach().cpu().numpy()\n",
    "        pred_idx = int(confidences.argmax())\n",
    "        pred_label = self.model.config.id2label[pred_idx]\n",
    "        \n",
    "        # Generate SHAP explanations\n",
    "        embeddings = self.model.get_input_embeddings()(inputs[\"input_ids\"])\n",
    "        \n",
    "        def forward_func(embeds):\n",
    "            attention_mask = inputs[\"attention_mask\"]\n",
    "            outputs = self.model(inputs_embeds=embeds, attention_mask=attention_mask)\n",
    "            return F.softmax(outputs.logits, dim=-1)[:, pred_idx]\n",
    "        \n",
    "        baseline_embeds = torch.zeros_like(embeddings).repeat(5, 1, 1)\n",
    "        gradient_shap = GradientShap(forward_func)\n",
    "        attributions, _ = gradient_shap.attribute(\n",
    "            embeddings, \n",
    "            baselines=baseline_embeds, \n",
    "            n_samples=25, \n",
    "            stdevs=0.01, \n",
    "            return_convergence_delta=True\n",
    "        )\n",
    "        \n",
    "        token_attrib = attributions.sum(dim=-1).squeeze().detach().cpu()\n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0].detach().cpu().numpy())\n",
    "        \n",
    "        # Normalize attributions to [0,1]\n",
    "        token_attrib = (token_attrib - token_attrib.min()) / (token_attrib.max() - token_attrib.min() + 1e-8)\n",
    "        token_explanations = list(zip(tokens, token_attrib.numpy().tolist()))\n",
    "        \n",
    "        # Get top contributing tokens (excluding special tokens)\n",
    "        top_tokens = sorted(\n",
    "            [(tok, attr) for tok, attr in token_explanations if tok not in ['[CLS]', '[SEP]', '[PAD]']],\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True\n",
    "        )[:5]\n",
    "        \n",
    "        return {\n",
    "            \"predicted_label\": pred_label,\n",
    "            \"confidence\": float(confidences[pred_idx]),\n",
    "            \"explanation\": f\"‚úì Top contributing tokens: {', '.join([f'{tok}({attr:.3f})' for tok, attr in top_tokens])}\",\n",
    "            \"all_attributions\": token_explanations\n",
    "        }\n",
    "\n",
    "print(\"‚úì SHAP comparison classes loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5859cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models for SHAP comparison...\n",
      "‚úì Both models loaded (same weights, different output formats)\n"
     ]
    }
   ],
   "source": [
    "# Load models (reusing same model path for fair comparison)\n",
    "print(\"Loading models for SHAP comparison...\")\n",
    "baseline_softmax_only = BaselineClassifierSoftmaxOnly(ENHANCED_MODEL_PATH, device=DEVICE)\n",
    "enhanced_with_shap = EnhancedClassifierWithSHAP(ENHANCED_MODEL_PATH, device=DEVICE)\n",
    "print(\"‚úì Both models loaded (same weights, different output formats)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a54a05c",
   "metadata": {},
   "source": [
    "### Side-by-Side Comparison: Softmax Only vs Softmax + SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53455b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST CASE 1\n",
      "================================================================================\n",
      "Input: \"High fever, severe headache, muscle pain, joint pain, rash on chest\"\n",
      "Expected: Classic dengue symptoms - should highlight 'fever', 'rash', 'joint pain'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[BASELINE - Softmax Only]\n",
      "  Prediction: Dengue\n",
      "  Confidence: 0.6455\n",
      "  Explanation: ‚ö†Ô∏è No explanation available (softmax only)\n",
      "\n",
      "[ENHANCED - Softmax + SHAP]\n",
      "  Prediction: Dengue\n",
      "  Confidence: 0.6455\n",
      "  Explanation: ‚úì Top contributing tokens: ƒ†muscle(1.000), ƒ†fever(0.598), ƒ†joint(0.504), ƒ†headache(0.414), ƒ†severe(0.271)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "üìä INTERPRETATION:\n",
      "  ‚Ä¢ Baseline: Gives prediction but no insight into reasoning\n",
      "  ‚Ä¢ Enhanced: Shows which tokens (symptoms) drove the decision\n",
      "  ‚Ä¢ Clinical Value: Clinician can validate if model focused on correct symptoms\n",
      "\n",
      "================================================================================\n",
      "TEST CASE 2\n",
      "================================================================================\n",
      "Input: \"Persistent cough with chest pain and difficulty breathing\"\n",
      "Expected: Respiratory symptoms - should highlight 'cough', 'chest', 'breathing'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[BASELINE - Softmax Only]\n",
      "  Prediction: Pneumonia\n",
      "  Confidence: 0.9276\n",
      "  Explanation: ‚ö†Ô∏è No explanation available (softmax only)\n",
      "\n",
      "[ENHANCED - Softmax + SHAP]\n",
      "  Prediction: Pneumonia\n",
      "  Confidence: 0.9276\n",
      "  Explanation: ‚úì Top contributing tokens: ƒ†cough(1.000), ƒ†pain(0.870), ƒ†and(0.422), istent(0.414), Pers(0.381)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "üìä INTERPRETATION:\n",
      "  ‚Ä¢ Baseline: Gives prediction but no insight into reasoning\n",
      "  ‚Ä¢ Enhanced: Shows which tokens (symptoms) drove the decision\n",
      "  ‚Ä¢ Clinical Value: Clinician can validate if model focused on correct symptoms\n",
      "\n",
      "================================================================================\n",
      "TEST CASE 3\n",
      "================================================================================\n",
      "Input: \"Sudden high fever with rose spots on abdomen and sustained fever pattern\"\n",
      "Expected: Typhoid indicators - should highlight 'rose spots', 'sustained fever'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[BASELINE - Softmax Only]\n",
      "  Prediction: Typhoid\n",
      "  Confidence: 0.9052\n",
      "  Explanation: ‚ö†Ô∏è No explanation available (softmax only)\n",
      "\n",
      "[ENHANCED - Softmax + SHAP]\n",
      "  Prediction: Typhoid\n",
      "  Confidence: 0.9052\n",
      "  Explanation: ‚úì Top contributing tokens: ƒ†abdomen(0.964), den(0.612), ƒ†pattern(0.579), ƒ†spots(0.532), ƒ†high(0.495)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "üìä INTERPRETATION:\n",
      "  ‚Ä¢ Baseline: Gives prediction but no insight into reasoning\n",
      "  ‚Ä¢ Enhanced: Shows which tokens (symptoms) drove the decision\n",
      "  ‚Ä¢ Clinical Value: Clinician can validate if model focused on correct symptoms\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "explainability_test_cases = [\n",
    "    {\n",
    "        \"text\": \"High fever, severe headache, muscle pain, joint pain, rash on chest\",\n",
    "        \"expected_focus\": \"Classic dengue symptoms - should highlight 'fever', 'rash', 'joint pain'\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Persistent cough with chest pain and difficulty breathing\",\n",
    "        \"expected_focus\": \"Respiratory symptoms - should highlight 'cough', 'chest', 'breathing'\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Sudden high fever with rose spots on abdomen and sustained fever pattern\",\n",
    "        \"expected_focus\": \"Typhoid indicators - should highlight 'rose spots', 'sustained fever'\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for idx, case in enumerate(explainability_test_cases, 1):\n",
    "    text = case[\"text\"]\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TEST CASE {idx}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Input: \\\"{text}\\\"\")\n",
    "    print(f\"Expected: {case['expected_focus']}\")\n",
    "    print(f\"\\n{'-'*80}\")\n",
    "    \n",
    "    # Baseline: Softmax only\n",
    "    baseline_result = baseline_softmax_only.predict(text)\n",
    "    print(f\"\\n[BASELINE - Softmax Only]\")\n",
    "    print(f\"  Prediction: {baseline_result['predicted_label']}\")\n",
    "    print(f\"  Confidence: {baseline_result['confidence']:.4f}\")\n",
    "    print(f\"  Explanation: {baseline_result['explanation']}\")\n",
    "    \n",
    "    # Enhanced: Softmax + SHAP\n",
    "    enhanced_result = enhanced_with_shap.predict_with_explanation(text)\n",
    "    print(f\"\\n[ENHANCED - Softmax + SHAP]\")\n",
    "    print(f\"  Prediction: {enhanced_result['predicted_label']}\")\n",
    "    print(f\"  Confidence: {enhanced_result['confidence']:.4f}\")\n",
    "    print(f\"  Explanation: {enhanced_result['explanation']}\")\n",
    "    \n",
    "    print(f\"\\n{'-'*80}\")\n",
    "    print(\"üìä INTERPRETATION:\")\n",
    "    print(f\"  ‚Ä¢ Baseline: Gives prediction but no insight into reasoning\")\n",
    "    print(f\"  ‚Ä¢ Enhanced: Shows which tokens (symptoms) drove the decision\")\n",
    "    print(f\"  ‚Ä¢ Clinical Value: Clinician can validate if model focused on correct symptoms\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
